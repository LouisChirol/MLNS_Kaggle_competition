{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape:  (10496, 3)\n",
      "Test set shape:  (3498, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>923</th>\n",
       "      <th>924</th>\n",
       "      <th>925</th>\n",
       "      <th>926</th>\n",
       "      <th>927</th>\n",
       "      <th>928</th>\n",
       "      <th>929</th>\n",
       "      <th>930</th>\n",
       "      <th>931</th>\n",
       "      <th>932</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1    2    3    4    5    6    7    8    9    10   ...  923  924  925  926  \\\n",
       "0                                                    ...                       \n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "5    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   927  928  929  930  931  932  \n",
       "0                                \n",
       "0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "5    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 932 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive train set shape:  (5248, 3)\n",
      "Negative train set shape:  (5248, 3)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load train samples\n",
    "with open(\"train.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_set = list(reader)\n",
    "train_set = [element[0].split(\" \") for element in train_set]\n",
    "train_set = np.array(train_set).astype(np.int32)\n",
    "print(\"Train set shape: \", train_set.shape)\n",
    "\n",
    "\n",
    "with open(\"test.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_set = list(reader)\n",
    "test_set = [element[0].split(\" \") for element in test_set]\n",
    "test_set = np.array(test_set).astype(np.int32)\n",
    "print(\"Test set shape: \", test_set.shape)\n",
    "\n",
    "\n",
    "# Load node_information.csv\n",
    "node_info = pd.read_csv(\"node_information.csv\", header=None).astype(np.int32).set_index(0)\n",
    "display(node_info.head(3))\n",
    "\n",
    "\n",
    "# Separate the positive and negative examples\n",
    "pos_train_set = train_set[train_set[:, 2] == 1]\n",
    "neg_train_set = train_set[train_set[:, 2] == 0]\n",
    "\n",
    "print(\"Positive train set shape: \", pos_train_set.shape)\n",
    "print(\"Negative train set shape: \", neg_train_set.shape)\n",
    "\n",
    "# Use the train_set to create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph and features from node_info\n",
    "for node in node_info.index:\n",
    "    G.add_node(node, features=node_info.loc[node])\n",
    "\n",
    "for element in pos_train_set:\n",
    "    G.add_edge(element[0], element[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2380\\2481163594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Louis\\anaconda3\\envs\\DL_tf\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"with_labels\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"labels\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mdraw_networkx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis_off\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Louis\\anaconda3\\envs\\DL_tf\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py\u001b[0m in \u001b[0;36mdraw_networkx\u001b[1;34m(G, pos, arrows, with_labels, **kwds)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspring_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# default to spring layout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[0mdraw_networkx_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnode_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Louis\\anaconda3\\envs\\DL_tf\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36margmap_spring_layout_1\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplitext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Louis\\anaconda3\\envs\\DL_tf\\lib\\site-packages\\networkx\\drawing\\layout.py\u001b[0m in \u001b[0;36mspring_layout\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# sparse solver for large graphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_scipy_sparse_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfixed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;31m# We must adjust k by domain size for layouts not near 1x1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Louis\\anaconda3\\envs\\DL_tf\\lib\\site-packages\\networkx\\convert_matrix.py\u001b[0m in \u001b[0;36mto_scipy_sparse_array\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdiag_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdiag_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoo_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw(G, with_labels=True, node_size=10, font_size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node:  4408\n",
      "Features:  1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "      ..\n",
      "928    0\n",
      "929    0\n",
      "930    0\n",
      "931    0\n",
      "932    0\n",
      "Name: 4408, Length: 932, dtype: int32\n",
      "Neighbors:  [6363, 5389]\n"
     ]
    }
   ],
   "source": [
    "# Select a random node and plot its neighbors and features\n",
    "node = np.random.choice(G.nodes())\n",
    "print(\"Node: \", node)\n",
    "print(\"Features: \", G.nodes[node][\"features\"])\n",
    "print(\"Neighbors: \", list(G.neighbors(node)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a pair of nodes and build features from their individual features and the graph\n",
    "def build_features(node1, node2):\n",
    "    features = []\n",
    "    features.append(G.nodes[node1][\"features\"])\n",
    "    features.append(G.nodes[node2][\"features\"])\n",
    "\n",
    "    features.append(G.nodes[node1][\"features\"] - G.nodes[node2][\"features\"])\n",
    "    features.append(G.nodes[node1][\"features\"] * G.nodes[node2][\"features\"])\n",
    "\n",
    "    # features.append(G.nodes[node1][\"features\"] / G.nodes[node2][\"features\"])\n",
    "    # features.append(G.nodes[node2][\"features\"] / G.nodes[node1][\"features\"])\n",
    "\n",
    "    features.append(np.array([len(list(nx.common_neighbors(G, node1, node2)))]))\n",
    "    features.append(np.array(list(nx.jaccard_coefficient(G, [(node1, node2)]))[-1]))\n",
    "    features.append(np.array(list(nx.resource_allocation_index(G, [(node1, node2)]))[-1]))\n",
    "    # features.append(np.array(list(nx.adamic_adar_index(G, [(node1, node2)]))[-1]))\n",
    "    features.append(np.array(list(nx.preferential_attachment(G, [(node1, node2)]))[-1]))\n",
    "    features.append(np.array([nx.shortest_path_length(G, node1, node2)]))\n",
    "    features.append(np.array([nx.clustering(G, node1)]))\n",
    "    features.append(np.array([nx.clustering(G, node2)]))\n",
    "    features.append(np.array([nx.clustering(G, node1) - nx.clustering(G, node2)]))\n",
    "    features.append(np.array([nx.clustering(G, node2) - nx.clustering(G, node1)]))\n",
    "    features.append(np.array([nx.clustering(G, node1) * nx.clustering(G, node2)]))\n",
    "    \n",
    "    # features.append(np.array([nx.clustering(G, node1) / nx.clustering(G, node2)]))\n",
    "    # features.append(np.array([nx.clustering(G, node2) / nx.clustering(G, node1)]))\n",
    "    return np.concatenate(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape:  (10496, 3744)\n"
     ]
    }
   ],
   "source": [
    "# Build features for the positive and negative train sets\n",
    "pos_features = np.array([build_features(element[0], element[1]) for element in pos_train_set])\n",
    "neg_features = np.array([build_features(element[0], element[1]) for element in neg_train_set])\n",
    "\n",
    "# Build features for the test set\n",
    "test_features = np.array([build_features(element[0], element[1]) for element in test_set])\n",
    "\n",
    "# Build the labels for the train set\n",
    "pos_labels = np.ones(pos_features.shape[0])\n",
    "neg_labels = np.zeros(neg_features.shape[0])\n",
    "train_labels = np.concatenate([pos_labels, neg_labels])\n",
    "\n",
    "# Build the features for the train set\n",
    "train_features = np.concatenate([pos_features, neg_features])\n",
    "\n",
    "print(\"Train features shape: \", train_features.shape)\n",
    "\n",
    "# Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8692835365853658\n",
      "Train f1 score:  0.853387475956401\n"
     ]
    }
   ],
   "source": [
    "# Call a classifier and train it\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=0)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Print the accuracy on the train set\n",
    "print(\"Train accuracy: \", clf.score(train_features, train_labels))\n",
    "\n",
    "# Print the f1 score on the train set\n",
    "print(\"Train f1 score: \", f1_score(train_labels, clf.predict(train_features)))\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_labels_pred = clf.predict(test_features)\n",
    "\n",
    "pred_zip = zip(np.array(range(len(test_set))), test_labels_pred)\n",
    "\n",
    "with open(\"RF_predictions.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(i for i in [\"ID\", \"Predicted\"])\n",
    "    for row in pred_zip:\n",
    "         csv_out.writerow(row)\n",
    "    pred.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier gave the best results yet (0.68 on Kaggle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  1.0\n",
      "Train f1 score:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\anaconda3\\envs\\DL_tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Call a classifier and train it\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_features, train_labels)\n",
    "\n",
    "train_preds = logreg.predict(train_features)\n",
    "test_preds = logreg.predict(test_features)\n",
    "\n",
    "# Print the accuracy on the train set\n",
    "print(\"Train accuracy: \", logreg.score(train_features, train_labels))\n",
    "\n",
    "# Print the f1 score on the train set\n",
    "print(\"Train f1 score: \", f1_score(train_labels, logreg.predict(train_features)))\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_labels_pred = logreg.predict(test_features)\n",
    "\n",
    "pred_zip = zip(np.array(range(len(test_set))), test_labels_pred)\n",
    "\n",
    "with open(\"LogReg_predictions.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(i for i in [\"ID\", \"Predicted\"])\n",
    "    for row in pred_zip:\n",
    "         csv_out.writerow(row)\n",
    "    pred.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the Kaggle score for the prediction (0.60), this classifier overfits a lot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average loss= 0.6184, Average accuracy= 0.6490\n",
      "Epoch 2 - Average loss= 0.4214, Average accuracy= 0.8160\n",
      "Epoch 3 - Average loss= 0.2643, Average accuracy= 0.8917\n",
      "Epoch 4 - Average loss= 0.1731, Average accuracy= 0.9353\n",
      "Epoch 5 - Average loss= 0.1241, Average accuracy= 0.9510\n",
      "Epoch 6 - Average loss= 0.1019, Average accuracy= 0.9632\n",
      "Epoch 7 - Average loss= 0.0767, Average accuracy= 0.9741\n",
      "Epoch 8 - Average loss= 0.0558, Average accuracy= 0.9803\n",
      "Epoch 9 - Average loss= 0.0657, Average accuracy= 0.9814\n",
      "Epoch 10 - Average loss= 0.0475, Average accuracy= 0.9843\n",
      "Epoch 11 - Average loss= 0.0404, Average accuracy= 0.9867\n",
      "Epoch 12 - Average loss= 0.0380, Average accuracy= 0.9877\n",
      "Epoch 13 - Average loss= 0.0431, Average accuracy= 0.9903\n",
      "Epoch 14 - Average loss= 0.0399, Average accuracy= 0.9909\n",
      "Epoch 15 - Average loss= 0.0240, Average accuracy= 0.9925\n"
     ]
    }
   ],
   "source": [
    "# Classify with a neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a dataset class\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Define a neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training, p=self.dropout_rate)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training, p=self.dropout_rate)\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, training=self.training, p=self.dropout_rate)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "# Define a function to train the model with tqdm\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.float()\n",
    "        target = target.unsqueeze(-1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        output = output.cpu().detach().round().numpy()\n",
    "        target = target.cpu().detach().numpy()\n",
    "        accuracy = (output == target).sum() / len(target)\n",
    "        accuracy_history.append(accuracy)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch} - Average loss= {np.mean(loss_history):.4f}, Average accuracy= {np.mean(accuracy_history):.4f}')\n",
    "\n",
    "\n",
    "# Define a function to predict the labels for the test set\n",
    "def predict(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_labels_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            data = data.float()\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.cpu().detach().round().numpy()\n",
    "\n",
    "            test_labels_pred.extend(pred)\n",
    "\n",
    "    return test_labels_pred\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "input_size = train_features.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "dropout_rate = 0.3\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "learning_rate = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "model = Net(input_size, hidden_size, output_size, dropout_rate).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the train and test datasets\n",
    "train_dataset = GraphDataset(train_features, train_labels)\n",
    "test_dataset = GraphDataset(test_features, np.zeros(test_features.shape[0]))\n",
    "\n",
    "# Define the train and test dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_labels_pred = predict(model, device, test_loader)\n",
    "test_labels_pred = [e[0] for e in test_labels_pred]\n",
    "\n",
    "pred_zip = zip(np.array(range(len(test_set))), test_labels_pred)\n",
    "\n",
    "with open(\"NN_predictions.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(i for i in [\"ID\", \"Predicted\"])\n",
    "    for row in pred_zip:\n",
    "         csv_out.writerow(row)\n",
    "    pred.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disappointing results on Kaggle (0.66)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
